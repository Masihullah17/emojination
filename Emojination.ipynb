{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/gamer/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/gamer/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/gamer/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "    \n",
    "classifier = load_model('/home/gamer/DeepLearningCV/Trained Models/emotion_little_vgg_new.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = {0: 'Angry', 1: 'Fear', 2: 'Happy', 3: 'Neutral', 4: 'Sad', 5: 'Surprise'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_detector(img):\n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return (0,0,0,0), np.zeros((48,48), np.uint8), img\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "\n",
    "    try:\n",
    "        roi_gray = cv2.resize(roi_gray, (48, 48), interpolation = cv2.INTER_AREA)\n",
    "    except:\n",
    "        return (x,w,y,h), np.zeros((48,48), np.uint8), img\n",
    "    return (x,w,y,h), roi_gray, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_test(im,pred,x,y,w,h):\n",
    "    img1 = im\n",
    "    rows,cols,channels = img1.shape\n",
    "    \n",
    "    if w<=rows and h<=cols:\n",
    "        w = w \n",
    "        h = h\n",
    "    else:\n",
    "        w = rows\n",
    "        h = cols\n",
    "\n",
    "    img2 = cv2.resize(cv2.imread('./emojis/'+ pred + '.png'),(w,h))\n",
    "    \n",
    "    roi = img1[y:y+h, x:x+w ]\n",
    "\n",
    "    # Now create a mask of logo and create its inverse mask also\n",
    "    img2gray = cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY)\n",
    "    ret, mask = cv2.threshold(img2gray, 10, 255, cv2.THRESH_BINARY)\n",
    "    mask_inv = cv2.bitwise_not(mask)\n",
    "\n",
    "    # Now black-out the area of logo in ROI\n",
    "    img1_bg = cv2.bitwise_and(roi,roi,mask = mask_inv)\n",
    "\n",
    "    # Take only region of logo from logo image.\n",
    "    img2_fg = cv2.bitwise_and(img2,img2,mask = mask)\n",
    "\n",
    "    # Put logo in ROI and modify the main image\n",
    "    dst = cv2.add(img1_bg,img2_fg)\n",
    "    img1[y:y+h, x:x+w ] = dst\n",
    "\n",
    "    return img1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def game(boolean,flag,time,image,label,count,fail):\n",
    "    label_position = (20, 50)\n",
    "    label_position1 = (20, 90)\n",
    "    if boolean == True:\n",
    "        r = random.randint(0,5)\n",
    "        label = class_labels[r]\n",
    "        count = count + 1\n",
    "        label_position = (2, 2)\n",
    "        flag = True\n",
    "        cv2.putText(image, 'Can you be ' + label + '?', label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (255,255,255), 3)\n",
    "    elif time < 25:\n",
    "        cv2.putText(image, 'Can you be ' + label + '?', label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (255,255,255), 3)\n",
    "    else:\n",
    "        cv2.putText(image, 'Can you be ' + label + '?', label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (255,255,255), 3)\n",
    "        cv2.putText(image, 'Wrong, Try again!', label_position1 , cv2.FONT_HERSHEY_SIMPLEX,1, (255,255,255), 3)\n",
    "        if flag == True:\n",
    "            fail = fail + 1\n",
    "            flag = False\n",
    "        \n",
    "    return image,label,count,fail,flag\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.0) /io/opencv/modules/core/src/arithm.cpp:245: error: (-215:Assertion failed) (mtype == CV_8U || mtype == CV_8S) && _mask.sameSize(*psrc1) in function 'binary_op'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-0a4a28a716ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrect\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrect\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrect\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrect\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mboolean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-9a4d1066092f>\u001b[0m in \u001b[0;36mdraw_test\u001b[0;34m(im, pred, x, y, w, h)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Now black-out the area of logo in ROI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mimg1_bg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbitwise_and\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mroi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_inv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# Take only region of logo from logo image.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.1.0) /io/opencv/modules/core/src/arithm.cpp:245: error: (-215:Assertion failed) (mtype == CV_8U || mtype == CV_8S) && _mask.sameSize(*psrc1) in function 'binary_op'\n"
     ]
    }
   ],
   "source": [
    "face_classifier = cv2.CascadeClassifier('./Haarcascades/haarcascade_frontalface_default.xml')\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "boolean = True\n",
    "q = class_labels[3]\n",
    "time = 0\n",
    "count = 0\n",
    "fail = 0\n",
    "flag = False\n",
    "while True:\n",
    "    time = time + 1\n",
    "    ret, frame = cap.read()\n",
    "    rect, face, image = face_detector(frame)\n",
    "    BLACK = [0,0,0]\n",
    "    image = cv2.copyMakeBorder(image,300, 0, 0,0 ,cv2.BORDER_CONSTANT,value=BLACK)\n",
    "    if np.sum([face]) != 0.0:\n",
    "        roi = face.astype(\"float\") / 255.0\n",
    "        roi = img_to_array(roi)\n",
    "        roi = np.expand_dims(roi, axis=0)\n",
    "        image,q,count,fail,flag = game(boolean,flag,time,image,q,count,fail)\n",
    "\n",
    "\n",
    "        # make a prediction on the ROI, then lookup the class\n",
    "        preds = classifier.predict(roi)[0]\n",
    "        label = class_labels[preds.argmax()]  \n",
    "        predicted = draw_test(image,label,rect[0],rect[1],rect[2],rect[3])\n",
    "        if q == label:\n",
    "            boolean = True\n",
    "            time = 0\n",
    "        else:\n",
    "            boolean = False\n",
    "        #label_position = (rect[0] + int((rect[1]/2)), rect[2] + 25)\n",
    "        #cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,2, (0,255,0), 3)\n",
    "    else:\n",
    "        predicted = image\n",
    "        cv2.putText(predicted, \"No Face Found\", (20, 60) , cv2.FONT_HERSHEY_SIMPLEX,2, (0,255,0), 3)\n",
    "\n",
    "    cv2.imshow('Emojinator', predicted)\n",
    "    if cv2.waitKey(1) == 13 or count == 10: #13 is the Enter Key\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()    \n",
    "\n",
    "# result = cv2.resize(cv2.imread('./emojis/black.jpg'),(100,100))\n",
    "# cv2.putText(result, str((count-fail)) + '/' + str(count), (20, 60) , cv2.FONT_HERSHEY_SIMPLEX,1, (255,255,255), 3)\n",
    "# cv2.imshow('Reusults',result)\n",
    "print('Your Score : ' + str(count-fail) + '/' + str(count)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
